{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04184d5a",
   "metadata": {},
   "source": [
    "# **Black-Scholes PINN Approximator**\n",
    "In this notebook, I'll be approximating the **Black-Scholes** equation using a **Physics-Informed Neural Network** or **PINN**. This will be foundational for when we scale up to the **Heston Model**. We will also cross-validate the data in this notebook with the solution found in our RK4 numerical solver and the PINN will be optimized via a **Sweep**.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "$$\n",
    "\\frac{\\partial V}{\\partial t} + \\frac{1}{2}\\sigma^2 S^2 \\frac{\\partial^2 V}{\\partial S^2} + rS \\frac{\\partial V}{\\partial S} - rV = 0\n",
    "$$\n",
    "<center>\n",
    "\n",
    "**Black-Scholes PDE**\n",
    "</center>\n",
    "\n",
    "Where:\n",
    "* $V$: Option price\n",
    "* $t$: Time\n",
    "* $S$: Price of the underlying asset\n",
    "* $\\sigma$: Volatility of the underlying asset's returns\n",
    "* $r$: Risk-free interest rate\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbdbfe9",
   "metadata": {},
   "source": [
    "## **Initialize Model + Define Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4411ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Manually set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class BlackScholesPINN(nn.Module):\n",
    "    def __init__(self, input_dim=2, output_dim=1, hidden_layers=4, neurons_per_layer=64, activation_fn=nn.Tanh()):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "\n",
    "        # Input layer\n",
    "        layers.append(nn.Linear(input_dim, neurons_per_layer))\n",
    "        layers.append(activation_fn)\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(hidden_layers - 1):\n",
    "            layers.append(nn.Linear(neurons_per_layer, neurons_per_layer))\n",
    "            layers.append(activation_fn)\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(neurons_per_layer, output_dim))\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Black-Scholes parameters (match with RK4 solver)\n",
    "r = 0.05          # Risk-free rate\n",
    "sigma = 0.2       # Volatility\n",
    "K = 100           # Strike price\n",
    "T = 1.0           # Time to maturity (in years)\n",
    "S_max = 250       # Max stock price in spatial domain\n",
    "S_min = 0         # Min stock price\n",
    "N = 500           # Number of spatial grid points\n",
    "\n",
    "# Create spatial grid\n",
    "S = torch.linspace(S_min, S_max, N).view(-1, 1).requires_grad_()\n",
    "t = torch.linspace(0, T, N).view(-1, 1).requires_grad_()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01445ed1",
   "metadata": {},
   "source": [
    "## **Define Losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70b87e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_loss(model, S, t):\n",
    "    S.requires_grad_(True)\n",
    "    t.requires_grad_(True)\n",
    "    X = torch.cat((S, t), dim=1)\n",
    "    V = model(X)\n",
    "\n",
    "    V_t = torch.autograd.grad(V, t, grad_outputs=torch.ones_like(V), create_graph=True)[0]\n",
    "    V_S = torch.autograd.grad(V, S, grad_outputs=torch.ones_like(V), create_graph=True)[0]\n",
    "    V_SS = torch.autograd.grad(V_S, S, grad_outputs=torch.ones_like(V_S), create_graph=True)[0]\n",
    "\n",
    "    residual = V_t + 0.5 * sigma**2 * S**2 * V_SS + r * S * V_S - r * V\n",
    "    return torch.mean(residual.pow(2))\n",
    "\n",
    "\n",
    "def boundary_loss(model, t):\n",
    "    S0 = torch.zeros_like(t)\n",
    "    S_high = torch.full_like(t, S_max)\n",
    "\n",
    "    bc_low = model(torch.cat((S0, t), dim=1))\n",
    "    bc_high = model(torch.cat((S_high, t), dim=1))\n",
    "    expected_high = S_max - K * torch.exp(-r * (T - t))\n",
    "\n",
    "    return torch.mean(bc_low.pow(2)) + torch.mean((bc_high - expected_high).pow(2))\n",
    "\n",
    "\n",
    "def initial_loss(model, S):\n",
    "    t0 = torch.zeros_like(S)\n",
    "    X0 = torch.cat((S, t0), dim=1)\n",
    "\n",
    "    V_pred = model(X0)\n",
    "    V_true = torch.clamp(S - K, min=0.0)\n",
    "\n",
    "    return torch.mean((V_pred - V_true).pow(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e66605c",
   "metadata": {},
   "source": [
    "## **Training Loop**\n",
    "Due to the complexity of this equation, we add in an adaptive stepper. After trial and error with different weights, it seemed like the next most important hyperparemeter to be tuned was the **learning rate**. I looked up various ways to do adaptive stepping and I stumbled across the **ReduceLROnPlateau** function within the PyTorch library. This function will monitor our total loss and reduce our learning rate when we begin to plateau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebdbe6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights - PDE: 3.547, BC: 1.854, IC: 0.168\n",
      "Epoch 0, Loss: 64.633, PDE Loss: 14.234, BC Loss: 7.627, IC Loss: 0.017, LR: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tobys\\miniconda3\\envs\\star-pinn\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss: 3.855, PDE Loss: 0.633, BC Loss: 0.065, IC Loss: 8.871, LR: 0.000500\n",
      "Epoch 1000, Loss: 1.598, PDE Loss: 0.164, BC Loss: 0.106, IC Loss: 4.873, LR: 0.000500\n",
      "Epoch 1500, Loss: 0.721, PDE Loss: 0.078, BC Loss: 0.050, IC Loss: 2.096, LR: 0.000500\n",
      "Epoch 2000, Loss: 0.456, PDE Loss: 0.057, BC Loss: 0.025, IC Loss: 1.227, LR: 0.000500\n",
      "Epoch 2500, Loss: 0.372, PDE Loss: 0.046, BC Loss: 0.019, IC Loss: 1.035, LR: 0.000500\n",
      "Epoch 3000, Loss: 0.331, PDE Loss: 0.041, BC Loss: 0.015, IC Loss: 0.941, LR: 0.000500\n",
      "Epoch 3500, Loss: 0.306, PDE Loss: 0.038, BC Loss: 0.012, IC Loss: 0.876, LR: 0.000500\n",
      "Epoch 4000, Loss: 0.286, PDE Loss: 0.036, BC Loss: 0.010, IC Loss: 0.824, LR: 0.000500\n",
      "Epoch 4500, Loss: 0.268, PDE Loss: 0.034, BC Loss: 0.009, IC Loss: 0.773, LR: 0.000500\n",
      "Epoch 5000, Loss: 0.251, PDE Loss: 0.033, BC Loss: 0.008, IC Loss: 0.717, LR: 0.000500\n",
      "Epoch 5500, Loss: 0.235, PDE Loss: 0.031, BC Loss: 0.007, IC Loss: 0.665, LR: 0.000500\n",
      "Epoch 6000, Loss: 0.182, PDE Loss: 0.022, BC Loss: 0.009, IC Loss: 0.507, LR: 0.000500\n",
      "Epoch 6500, Loss: 0.164, PDE Loss: 0.021, BC Loss: 0.013, IC Loss: 0.387, LR: 0.000500\n",
      "Epoch 7000, Loss: 0.165, PDE Loss: 0.023, BC Loss: 0.015, IC Loss: 0.328, LR: 0.000500\n",
      "Epoch 7500, Loss: 0.157, PDE Loss: 0.022, BC Loss: 0.016, IC Loss: 0.289, LR: 0.000500\n",
      "Epoch 8000, Loss: 0.155, PDE Loss: 0.022, BC Loss: 0.011, IC Loss: 0.335, LR: 0.000500\n",
      "Epoch 8500, Loss: 0.143, PDE Loss: 0.019, BC Loss: 0.012, IC Loss: 0.313, LR: 0.000050\n",
      "Epoch 9000, Loss: 0.142, PDE Loss: 0.019, BC Loss: 0.012, IC Loss: 0.312, LR: 0.000005\n",
      "Epoch 9500, Loss: 0.142, PDE Loss: 0.019, BC Loss: 0.012, IC Loss: 0.312, LR: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Initialize model, optimizer, and training parameters\n",
    "model = BlackScholesPINN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "epochs = 10000\n",
    "loss_history = []\n",
    "\n",
    "# Weights for each loss component (tuned via trial and error)\n",
    "pde_weight = 3.547\n",
    "bc_weight = 1.854\n",
    "ic_weight = 0.168\n",
    "\n",
    "print(f'Weights - PDE: {pde_weight}, BC: {bc_weight}, IC: {ic_weight}')\n",
    "\n",
    "# Adaptive learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=400, min_lr=1e-7, verbose=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    V = model(torch.cat((S, t), dim=1))\n",
    "\n",
    "    # Compute losses\n",
    "    pde_l = pde_loss(model, S, t)\n",
    "    bc_l = boundary_loss(model, t)\n",
    "    ic_l = initial_loss(model, S)\n",
    "    total_loss = (pde_weight * pde_l) + (bc_weight * bc_l) + (ic_weight * ic_l)\n",
    "\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if isinstance(scheduler, ReduceLROnPlateau):\n",
    "        scheduler.step(total_loss)\n",
    "    else:\n",
    "        scheduler.step()\n",
    "\n",
    "    loss_history.append(total_loss.item())\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {total_loss.item():.3f}, PDE Loss: {pde_l.item():.3f}, BC Loss: {bc_l.item():.3f}, IC Loss: {ic_l.item():.3f}, LR: {current_lr:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e591eae2",
   "metadata": {},
   "source": [
    "### **Plot Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e078220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.title('Training Loss')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6a7be0",
   "metadata": {},
   "source": [
    "### **Sweep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab5e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "wandb: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
      "wandb: Paste an API key from your profile and hit enter:wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: No netrc file found, creating one.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\tobys\\_netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: y2ttpnwf\n",
      "Sweep URL: https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf\n",
      "Sweep ID: y2ttpnwf\n",
      "Run the following command in your terminal to start sweep agents:\n",
      "wandb agent y2ttpnwf\n",
      "\n",
      "Alternatively, to run agents directly in this notebook (for local testing):\n",
      "wandb.agent('y2ttpnwf', function=train_pinn_sweep, count=5)\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import math # For math.prod if needed for debugging\n",
    "\n",
    "\n",
    "# --- IMPORTANT: Your PINN Model and Loss Functions ---\n",
    "# Make sure your blackScholesPINN class, pde_loss, boundary_loss, initial_loss\n",
    "# functions, and S, t tensors are defined in previous cells or imported.\n",
    "# For example:\n",
    "# from your_module import blackScholesPINN, pde_loss, boundary_loss, initial_loss, S, t\n",
    "# If they are not globally available, you might need to pass them or define them inside train_pinn_sweep.\n",
    "# For simplicity, this assumes they are already defined when this cell runs.\n",
    "\n",
    "# Define the sweep configuration\n",
    "# We'll use 'random' search to efficiently explore the weight space.\n",
    "# The 'metric' defines what we are trying to optimize (minimize final_total_loss).\n",
    "# 'parameters' define the ranges/distributions for the hyperparameters we want to tune.\n",
    "\n",
    "sweep_config = {\n",
    "    'method': 'bayes', # or 'grid' or 'bayes'\n",
    "    'metric': {\n",
    "        'name': 'final_total_loss',\n",
    "        'goal': 'minimize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        # Initial Learning Rate (Still good to sweep, as it affects where scheduler starts)\n",
    "        'initial_lr': {\n",
    "            'min': 0.0001,\n",
    "            'max': 0.005,\n",
    "            'distribution': 'log_uniform_values' # Log uniform is good for LR\n",
    "        },\n",
    "        # Patience for LR scheduler (how long to wait before reducing)\n",
    "        'lr_patience': {\n",
    "            'min': 100,\n",
    "            'max': 500,\n",
    "            'distribution': 'int_uniform' # Integer values\n",
    "        },\n",
    "        # Factor for LR reduction (e.g., 0.1 for 10x, 0.5 for 2x)\n",
    "        'lr_factor': {\n",
    "            'min': 0.05,\n",
    "            'max': 0.5,\n",
    "            'distribution': 'uniform'\n",
    "        },\n",
    "        # Loss Weights - This is the core of this sweep\n",
    "        # We'll define them as relative scales, then normalize in the training function\n",
    "        # This allows you to explore their influence independently before normalizing.\n",
    "        'pde_weight_scale': {\n",
    "            'min': 0.01, # Min relative scale for PDE loss\n",
    "            'max': 10.0, # Max relative scale for PDE loss (can go higher if PDE is very hard)\n",
    "            'distribution': 'log_uniform_values'\n",
    "        },\n",
    "        'bc_weight_scale': {\n",
    "            'min': 0.1, # Min relative scale for BC loss\n",
    "            'max': 10.0, # Max relative scale for BC loss\n",
    "            'distribution': 'log_uniform_values'\n",
    "        },\n",
    "        'ic_weight_scale': {\n",
    "            'min': 0.1, # Min relative scale for IC loss\n",
    "            'max': 10.0, # Max relative scale for IC loss\n",
    "            'distribution': 'log_uniform_values'\n",
    "        },\n",
    "        # Network architecture (optional, but good to include in a later sweep)\n",
    "        # 'hidden_layers': {\n",
    "        #     'values': [4, 6, 8] # Number of hidden layers\n",
    "        # },\n",
    "        # 'neurons_per_layer': {\n",
    "        #     'values': [64, 128, 256] # Number of neurons per layer\n",
    "        # }\n",
    "    }\n",
    "}\n",
    "\n",
    "# The training function that will be run by each sweep agent\n",
    "def train_pinn_sweep():\n",
    "    # Initialize a new W&B run for this trial\n",
    "    wandb.init()\n",
    "\n",
    "    # Access hyperparameters for the current run\n",
    "    config = wandb.config\n",
    "\n",
    "    # Normalize weights to sum to 1, or use them as raw scaling factors\n",
    "    # It's often better to use them as raw scaling factors if you don't enforce a sum=1\n",
    "    # and let the network decide which loss needs more attention.\n",
    "    # If you want to enforce sum=1:\n",
    "    # total_scale = config.pde_weight_scale + config.bc_weight_scale + config.ic_weight_scale\n",
    "    # pde_weight = config.pde_weight_scale / total_scale\n",
    "    # bc_weight = config.bc_weight_scale / total_scale\n",
    "    # ic_weight = config.ic_weight_scale / total_scale\n",
    "    # Or, use them directly as they are more like penalty terms:\n",
    "    pde_weight = config.pde_weight_scale\n",
    "    bc_weight = config.bc_weight_scale\n",
    "    ic_weight = config.ic_weight_scale\n",
    "\n",
    "\n",
    "    # Initialize model and optimizer with hyperparameters from config\n",
    "    model = BlackScholesPINN()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.initial_lr)\n",
    "\n",
    "    # Adaptive learning rate scheduler using config values\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=config.lr_factor,\n",
    "        patience=config.lr_patience,\n",
    "        min_lr=1e-7, # Keep a very low min_lr\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    epochs = 10000 # Keep fixed for this sweep, or make it a sweep param too\n",
    "    \n",
    "    # Store individual loss components (optional but good for analysis)\n",
    "    run_pde_loss_history = []\n",
    "    run_bc_loss_history = []\n",
    "    run_ic_loss_history = []\n",
    "    run_total_loss_history = []\n",
    "\n",
    "    print(f\"Starting run with Weights: PDE={pde_weight:.2e}, BC={bc_weight:.2e}, IC={ic_weight:.2e}, \"\n",
    "          f\"Initial LR={config.initial_lr:.2e}, Patience={config.lr_patience}, Factor={config.lr_factor:.2f}\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Ensure S and t are on the correct device (e.g., GPU if available)\n",
    "        # S = S.to(device)\n",
    "        # t = t.to(device)\n",
    "        V = model(torch.cat((S, t), dim=1))\n",
    "\n",
    "        # Compute losses\n",
    "        pde_l = pde_loss(model, S, t)\n",
    "        bc_l = boundary_loss(model, t)\n",
    "        ic_l = initial_loss(model, S)\n",
    "        \n",
    "        # Calculate total loss using the swept weights\n",
    "        total_loss = (pde_weight * pde_l) + (bc_weight * bc_l) + (ic_weight * ic_l)\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Step the scheduler (pass total_loss for ReduceLROnPlateau)\n",
    "        scheduler.step(total_loss)\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        # Log metrics to W&B for each epoch\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"total_loss\": total_loss.item(),\n",
    "            \"pde_loss\": pde_l.item(),\n",
    "            \"bc_loss\": bc_l.item(),\n",
    "            \"ic_loss\": ic_l.item(),\n",
    "            \"learning_rate\": current_lr,\n",
    "            \"bc_loss_norm_factor\": bc_l.item() / (total_loss.item() + 1e-9), # Debugging loss contributions\n",
    "            \"ic_loss_norm_factor\": ic_l.item() / (total_loss.item() + 1e-9)\n",
    "        })\n",
    "\n",
    "        run_total_loss_history.append(total_loss.item())\n",
    "        run_pde_loss_history.append(pde_l.item())\n",
    "        run_bc_loss_history.append(bc_l.item())\n",
    "        run_ic_loss_history.append(ic_l.item())\n",
    "\n",
    "\n",
    "        if epoch % 500 == 0 or epoch == epochs - 1: # Print at intervals and at the very end\n",
    "            print(f'Epoch {epoch}, Total Loss: {total_loss.item():.6f}, '\n",
    "                  f'PDE Loss: {pde_l.item():.6f}, BC Loss: {bc_l.item():.6f}, '\n",
    "                  f'IC Loss: {ic_l.item():.6f}, '\n",
    "                  f'LR: {current_lr:.8f}')\n",
    "            \n",
    "    # Log the final total loss as the sweep metric\n",
    "    wandb.log({\"final_total_loss\": total_loss.item()})\n",
    "\n",
    "    # You can also log final individual losses\n",
    "    wandb.log({\n",
    "        \"final_pde_loss\": pde_l.item(),\n",
    "        \"final_bc_loss\": bc_l.item(),\n",
    "        \"final_ic_loss\": ic_l.item()\n",
    "    })\n",
    "    \n",
    "    # End the W&B run for this trial\n",
    "    wandb.finish()\n",
    "\n",
    "# --- Initialize and run the Sweep ---\n",
    "# Create a unique sweep ID. This will output instructions to run agents.\n",
    "# You can give your project a specific name here.\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"PINN_Loss_Weight_Sweep\")\n",
    "\n",
    "print(f\"Sweep ID: {sweep_id}\")\n",
    "print(\"Run the following command in your terminal to start sweep agents:\")\n",
    "print(f\"wandb agent {sweep_id}\")\n",
    "print(\"\\nAlternatively, to run agents directly in this notebook (for local testing):\")\n",
    "print(f\"wandb.agent('{sweep_id}', function=train_pinn_sweep, count=5)\") # Runs 5 trials in this cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f16876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 7u111nwv with config:\n",
      "wandb: \tbc_weight_scale: 0.13412992794188688\n",
      "wandb: \tic_weight_scale: 3.347607966549058\n",
      "wandb: \tinitial_lr: 0.0001092351964701568\n",
      "wandb: \tlr_factor: 0.09005100993384699\n",
      "wandb: \tlr_patience: 175\n",
      "wandb: \tpde_weight_scale: 8.27218631100438\n",
      "wandb: Currently logged in as: tobiassafie (tobiassafie-drexel-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tobys\\Desktop\\STAR\\dev_notebooks\\black_scholes\\wandb\\run-20250715_120631-7u111nwv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/7u111nwv' target=\"_blank\">deep-sweep-1</a></strong> to <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/7u111nwv' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/7u111nwv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run with Weights: PDE=8.27e+00, BC=1.34e-01, IC=3.35e+00, Initial LR=1.09e-04, Patience=175, Factor=0.09\n",
      "Epoch 0, Total Loss: 18352.226562, PDE Loss: 0.000321, BC Loss: 23356.525391, IC Loss: 4546.354980, LR: 0.00010924\n",
      "Epoch 500, Total Loss: 15893.483398, PDE Loss: 0.120971, BC Loss: 21058.675781, IC Loss: 3903.648438, LR: 0.00010924\n",
      "Epoch 1000, Total Loss: 14806.965820, PDE Loss: 0.252313, BC Loss: 19951.445312, IC Loss: 3623.122314, LR: 0.00010924\n",
      "Epoch 1500, Total Loss: 13844.230469, PDE Loss: 0.373473, BC Loss: 18999.003906, IC Loss: 3373.395508, LR: 0.00010924\n",
      "Epoch 2000, Total Loss: 12806.229492, PDE Loss: 0.898039, BC Loss: 18104.501953, IC Loss: 3097.867432, LR: 0.00010924\n",
      "Epoch 2500, Total Loss: 11868.165039, PDE Loss: 1.725671, BC Loss: 17174.468750, IC Loss: 2852.866943, LR: 0.00010924\n",
      "Epoch 3000, Total Loss: 11003.800781, PDE Loss: 2.980553, BC Loss: 16262.653320, IC Loss: 2628.096436, LR: 0.00010924\n",
      "Epoch 3500, Total Loss: 10204.859375, PDE Loss: 3.781827, BC Loss: 15400.189453, IC Loss: 2422.012695, LR: 0.00010924\n",
      "Epoch 4000, Total Loss: 9457.960938, PDE Loss: 4.247483, BC Loss: 14582.454102, IC Loss: 2230.512695, LR: 0.00010924\n",
      "Epoch 4500, Total Loss: 8755.507812, PDE Loss: 4.383970, BC Loss: 13799.461914, IC Loss: 2051.710449, LR: 0.00010924\n",
      "Epoch 5000, Total Loss: 8093.690430, PDE Loss: 4.366190, BC Loss: 13046.019531, IC Loss: 1884.244263, LR: 0.00010924\n",
      "Epoch 5500, Total Loss: 7469.097656, PDE Loss: 4.267520, BC Loss: 12320.227539, IC Loss: 1726.989746, LR: 0.00010924\n",
      "Epoch 6000, Total Loss: 6879.468750, PDE Loss: 4.136178, BC Loss: 11619.815430, IC Loss: 1579.243652, LR: 0.00010924\n",
      "Epoch 6500, Total Loss: 6322.959961, PDE Loss: 4.014193, BC Loss: 10943.369141, IC Loss: 1440.407837, LR: 0.00010924\n",
      "Epoch 7000, Total Loss: 5798.061035, PDE Loss: 3.883376, BC Loss: 10290.196289, IC Loss: 1310.103882, LR: 0.00010924\n",
      "Epoch 7500, Total Loss: 5303.117188, PDE Loss: 3.651508, BC Loss: 9659.900391, IC Loss: 1188.081055, LR: 0.00010924\n",
      "Epoch 8000, Total Loss: 4838.085449, PDE Loss: 3.382931, BC Loss: 9052.238281, IC Loss: 1074.177490, LR: 0.00010924\n",
      "Epoch 8500, Total Loss: 4403.127930, PDE Loss: 3.071292, BC Loss: 8467.580078, IC Loss: 968.442627, LR: 0.00010924\n",
      "Epoch 9000, Total Loss: 3996.956543, PDE Loss: 2.622446, BC Loss: 7907.359375, IC Loss: 870.666382, LR: 0.00010924\n",
      "Epoch 9500, Total Loss: 3617.157227, PDE Loss: 1.685097, BC Loss: 7377.380859, IC Loss: 780.763550, LR: 0.00010924\n",
      "Epoch 9999, Total Loss: 3264.320312, PDE Loss: 0.984975, BC Loss: 6870.037109, IC Loss: 697.421875, LR: 0.00010924\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>█████▇▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▁▁▁▁</td></tr><tr><td>bc_loss_norm_factor</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>final_bc_loss</td><td>▁</td></tr><tr><td>final_ic_loss</td><td>▁</td></tr><tr><td>final_pde_loss</td><td>▁</td></tr><tr><td>final_total_loss</td><td>▁</td></tr><tr><td>ic_loss</td><td>████▇▇▇▇▆▆▆▆▅▅▅▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>ic_loss_norm_factor</td><td>██████▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>pde_loss</td><td>▁▁▁▁▁▁▂▂▂▃▄▅▆▆▆████████▇▇▇▇▇▇▇▆▆▆▆▆▅▅▄▄▃</td></tr><tr><td>total_loss</td><td>███▇▇▇▆▆▆▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>6870.03711</td></tr><tr><td>bc_loss_norm_factor</td><td>2.10458</td></tr><tr><td>epoch</td><td>9999</td></tr><tr><td>final_bc_loss</td><td>6870.03711</td></tr><tr><td>final_ic_loss</td><td>697.42188</td></tr><tr><td>final_pde_loss</td><td>0.98497</td></tr><tr><td>final_total_loss</td><td>3264.32031</td></tr><tr><td>ic_loss</td><td>697.42188</td></tr><tr><td>ic_loss_norm_factor</td><td>0.21365</td></tr><tr><td>learning_rate</td><td>0.00011</td></tr><tr><td>pde_loss</td><td>0.98497</td></tr><tr><td>total_loss</td><td>3264.32031</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deep-sweep-1</strong> at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/7u111nwv' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/7u111nwv</a><br> View project at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250715_120631-7u111nwv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: plevtjf6 with config:\n",
      "wandb: \tbc_weight_scale: 0.10435944976896948\n",
      "wandb: \tic_weight_scale: 1.921105125806135\n",
      "wandb: \tinitial_lr: 0.00012593951021339675\n",
      "wandb: \tlr_factor: 0.4148741906117409\n",
      "wandb: \tlr_patience: 210\n",
      "wandb: \tpde_weight_scale: 2.0012060675151115\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tobys\\Desktop\\STAR\\dev_notebooks\\black_scholes\\wandb\\run-20250715_120717-plevtjf6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/plevtjf6' target=\"_blank\">true-sweep-2</a></strong> to <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/plevtjf6' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/plevtjf6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run with Weights: PDE=2.00e+00, BC=1.04e-01, IC=1.92e+00, Initial LR=1.26e-04, Patience=210, Factor=0.41\n",
      "Epoch 0, Total Loss: 10994.644531, PDE Loss: 0.000576, BC Loss: 23093.132812, IC Loss: 4468.603027, LR: 0.00012594\n",
      "Epoch 500, Total Loss: 9527.932617, PDE Loss: 0.171149, BC Loss: 20775.996094, IC Loss: 3830.825439, LR: 0.00012594\n",
      "Epoch 1000, Total Loss: 8817.951172, PDE Loss: 0.316173, BC Loss: 19566.402344, IC Loss: 3526.813477, LR: 0.00012594\n",
      "Epoch 1500, Total Loss: 8125.596680, PDE Loss: 0.773963, BC Loss: 18492.886719, IC Loss: 3224.258789, LR: 0.00012594\n",
      "Epoch 2000, Total Loss: 7443.634766, PDE Loss: 1.722545, BC Loss: 17432.300781, IC Loss: 2925.900391, LR: 0.00012594\n",
      "Epoch 2500, Total Loss: 6825.401367, PDE Loss: 3.552999, BC Loss: 16381.050781, IC Loss: 2659.288818, LR: 0.00012594\n",
      "Epoch 3000, Total Loss: 6262.577148, PDE Loss: 6.128798, BC Loss: 15390.551758, IC Loss: 2417.443115, LR: 0.00012594\n",
      "Epoch 3500, Total Loss: 5746.187988, PDE Loss: 7.699346, BC Loss: 14457.434570, IC Loss: 2197.698730, LR: 0.00012594\n",
      "Epoch 4000, Total Loss: 5267.199707, PDE Loss: 8.742281, BC Loss: 13570.438477, IC Loss: 1995.466553, LR: 0.00012594\n",
      "Epoch 4500, Total Loss: 4820.700195, PDE Loss: 9.169712, BC Loss: 12722.699219, IC Loss: 1808.654785, LR: 0.00012594\n",
      "Epoch 5000, Total Loss: 4402.896973, PDE Loss: 8.988742, BC Loss: 11910.020508, IC Loss: 1635.509277, LR: 0.00012594\n",
      "Epoch 5500, Total Loss: 4011.596436, PDE Loss: 8.467720, BC Loss: 11129.892578, IC Loss: 1474.745605, LR: 0.00012594\n",
      "Epoch 6000, Total Loss: 3645.403076, PDE Loss: 7.802796, BC Loss: 10380.872070, IC Loss: 1325.510986, LR: 0.00012594\n",
      "Epoch 6500, Total Loss: 3303.307617, PDE Loss: 7.122905, BC Loss: 9662.128906, IC Loss: 1187.191040, LR: 0.00012594\n",
      "Epoch 7000, Total Loss: 2984.024414, PDE Loss: 6.358320, BC Loss: 8973.154297, IC Loss: 1059.216797, LR: 0.00012594\n",
      "Epoch 7500, Total Loss: 2686.586670, PDE Loss: 5.495564, BC Loss: 8313.440430, IC Loss: 941.126404, LR: 0.00012594\n",
      "Epoch 8000, Total Loss: 2410.779785, PDE Loss: 4.440652, BC Loss: 7683.139160, IC Loss: 832.898254, LR: 0.00012594\n",
      "Epoch 8500, Total Loss: 2156.882080, PDE Loss: 3.739644, BC Loss: 7082.028320, IC Loss: 734.119995, LR: 0.00012594\n",
      "Epoch 9000, Total Loss: 1923.863770, PDE Loss: 3.192313, BC Loss: 6510.402344, IC Loss: 644.448486, LR: 0.00012594\n",
      "Epoch 9500, Total Loss: 1709.682129, PDE Loss: 2.539478, BC Loss: 5968.515137, IC Loss: 563.076477, LR: 0.00012594\n",
      "Epoch 9999, Total Loss: 1513.521484, PDE Loss: 1.858242, BC Loss: 5456.315918, IC Loss: 489.501892, LR: 0.00012594\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>███▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>bc_loss_norm_factor</td><td>▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>final_bc_loss</td><td>▁</td></tr><tr><td>final_ic_loss</td><td>▁</td></tr><tr><td>final_pde_loss</td><td>▁</td></tr><tr><td>final_total_loss</td><td>▁</td></tr><tr><td>ic_loss</td><td>██▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>ic_loss_norm_factor</td><td>█████▇▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>pde_loss</td><td>▁▁▁▁▁▁▁▁▁▁▂▂▂▃▃▄▄▆▇▇██████▇▆▆▆▅▅▄▄▄▄▃▃▃▃</td></tr><tr><td>total_loss</td><td>█▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>5456.31592</td></tr><tr><td>bc_loss_norm_factor</td><td>3.60505</td></tr><tr><td>epoch</td><td>9999</td></tr><tr><td>final_bc_loss</td><td>5456.31592</td></tr><tr><td>final_ic_loss</td><td>489.50189</td></tr><tr><td>final_pde_loss</td><td>1.85824</td></tr><tr><td>final_total_loss</td><td>1513.52148</td></tr><tr><td>ic_loss</td><td>489.50189</td></tr><tr><td>ic_loss_norm_factor</td><td>0.32342</td></tr><tr><td>learning_rate</td><td>0.00013</td></tr><tr><td>pde_loss</td><td>1.85824</td></tr><tr><td>total_loss</td><td>1513.52148</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">true-sweep-2</strong> at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/plevtjf6' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/plevtjf6</a><br> View project at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250715_120717-plevtjf6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: mfrgzgqa with config:\n",
      "wandb: \tbc_weight_scale: 0.8556516081795155\n",
      "wandb: \tic_weight_scale: 0.14209537162560515\n",
      "wandb: \tinitial_lr: 0.0038421092551517745\n",
      "wandb: \tlr_factor: 0.43661668077343857\n",
      "wandb: \tlr_patience: 223\n",
      "wandb: \tpde_weight_scale: 0.514111868930754\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tobys\\Desktop\\STAR\\dev_notebooks\\black_scholes\\wandb\\run-20250715_120804-mfrgzgqa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/mfrgzgqa' target=\"_blank\">happy-sweep-3</a></strong> to <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/mfrgzgqa' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/mfrgzgqa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run with Weights: PDE=5.14e-01, BC=8.56e-01, IC=1.42e-01, Initial LR=3.84e-03, Patience=223, Factor=0.44\n",
      "Epoch 0, Total Loss: 20473.832031, PDE Loss: 0.000226, BC Loss: 23181.398438, IC Loss: 4494.384766, LR: 0.00384211\n",
      "Epoch 500, Total Loss: 2220.410889, PDE Loss: 6.435989, BC Loss: 2562.761475, IC Loss: 170.808350, LR: 0.00384211\n",
      "Epoch 1000, Total Loss: 90.780716, PDE Loss: 9.264701, BC Loss: 98.067078, IC Loss: 14.823609, LR: 0.00384211\n",
      "Epoch 1500, Total Loss: 3.783523, PDE Loss: 0.543917, BC Loss: 3.045417, IC Loss: 6.320211, LR: 0.00384211\n",
      "Epoch 2000, Total Loss: 1.604048, PDE Loss: 0.660118, BC Loss: 0.654170, IC Loss: 4.960976, LR: 0.00384211\n",
      "Epoch 2500, Total Loss: 1.415956, PDE Loss: 0.071418, BC Loss: 0.490480, IC Loss: 6.752924, LR: 0.00384211\n",
      "Epoch 3000, Total Loss: 1123.213135, PDE Loss: 111.065765, BC Loss: 144.550735, IC Loss: 6632.360840, LR: 0.00384211\n",
      "Epoch 3500, Total Loss: 8.830765, PDE Loss: 6.925531, BC Loss: 5.128825, IC Loss: 6.205546, LR: 0.00073244\n",
      "Epoch 4000, Total Loss: 6.664271, PDE Loss: 4.433946, BC Loss: 4.280118, IC Loss: 5.084168, LR: 0.00013963\n",
      "Epoch 4500, Total Loss: 6.315832, PDE Loss: 4.101380, BC Loss: 4.101627, IC Loss: 4.910083, LR: 0.00001162\n",
      "Epoch 5000, Total Loss: 6.250167, PDE Loss: 4.041166, BC Loss: 4.066541, IC Loss: 4.877101, LR: 0.00000222\n",
      "Epoch 5500, Total Loss: 6.239147, PDE Loss: 4.030498, BC Loss: 4.061213, IC Loss: 4.870233, LR: 0.00000042\n",
      "Epoch 6000, Total Loss: 6.237532, PDE Loss: 4.029200, BC Loss: 4.059979, IC Loss: 4.870989, LR: 0.00000010\n",
      "Epoch 6500, Total Loss: 6.236584, PDE Loss: 4.028631, BC Loss: 4.059044, IC Loss: 4.872000, LR: 0.00000010\n",
      "Epoch 7000, Total Loss: 6.235557, PDE Loss: 4.028212, BC Loss: 4.057975, IC Loss: 4.872729, LR: 0.00000010\n",
      "Epoch 7500, Total Loss: 6.234373, PDE Loss: 4.027624, BC Loss: 4.057142, IC Loss: 4.871538, LR: 0.00000010\n",
      "Epoch 8000, Total Loss: 6.233052, PDE Loss: 4.027250, BC Loss: 4.056297, IC Loss: 4.868689, LR: 0.00000010\n",
      "Epoch 8500, Total Loss: 6.231564, PDE Loss: 4.026509, BC Loss: 4.055743, IC Loss: 4.864228, LR: 0.00000010\n",
      "Epoch 9000, Total Loss: 6.229926, PDE Loss: 4.026497, BC Loss: 4.053867, IC Loss: 4.864043, LR: 0.00000010\n",
      "Epoch 9500, Total Loss: 6.228130, PDE Loss: 4.026089, BC Loss: 4.052564, IC Loss: 4.860726, LR: 0.00000010\n",
      "Epoch 9999, Total Loss: 6.226145, PDE Loss: 4.025741, BC Loss: 4.050653, IC Loss: 4.859522, LR: 0.00000010\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>█▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bc_loss_norm_factor</td><td>█████▄▁▂▁▃▄▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>final_bc_loss</td><td>▁</td></tr><tr><td>final_ic_loss</td><td>▁</td></tr><tr><td>final_pde_loss</td><td>▁</td></tr><tr><td>final_total_loss</td><td>▁</td></tr><tr><td>ic_loss</td><td>█▆▃▁▁▁▁▁▁▁▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ic_loss_norm_factor</td><td>▁▁▁▁▁▄▆█▅▇▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>learning_rate</td><td>███████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>pde_loss</td><td>▁█▃▂▂▂▂▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>4.05065</td></tr><tr><td>bc_loss_norm_factor</td><td>0.65059</td></tr><tr><td>epoch</td><td>9999</td></tr><tr><td>final_bc_loss</td><td>4.05065</td></tr><tr><td>final_ic_loss</td><td>4.85952</td></tr><tr><td>final_pde_loss</td><td>4.02574</td></tr><tr><td>final_total_loss</td><td>6.22614</td></tr><tr><td>ic_loss</td><td>4.85952</td></tr><tr><td>ic_loss_norm_factor</td><td>0.7805</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>pde_loss</td><td>4.02574</td></tr><tr><td>total_loss</td><td>6.22614</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">happy-sweep-3</strong> at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/mfrgzgqa' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/mfrgzgqa</a><br> View project at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250715_120804-mfrgzgqa\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: plkmh4l3 with config:\n",
      "wandb: \tbc_weight_scale: 2.6753132805999504\n",
      "wandb: \tic_weight_scale: 3.3572675653430215\n",
      "wandb: \tinitial_lr: 0.00011097517297585704\n",
      "wandb: \tlr_factor: 0.4452751463847548\n",
      "wandb: \tlr_patience: 340\n",
      "wandb: \tpde_weight_scale: 1.3081020864308897\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tobys\\Desktop\\STAR\\dev_notebooks\\black_scholes\\wandb\\run-20250715_120850-plkmh4l3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/plkmh4l3' target=\"_blank\">electric-sweep-4</a></strong> to <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/plkmh4l3' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/plkmh4l3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run with Weights: PDE=1.31e+00, BC=2.68e+00, IC=3.36e+00, Initial LR=1.11e-04, Patience=340, Factor=0.45\n",
      "Epoch 0, Total Loss: 77401.781250, PDE Loss: 0.000219, BC Loss: 23261.667969, IC Loss: 4518.416504, LR: 0.00011098\n",
      "Epoch 500, Total Loss: 68659.468750, PDE Loss: 0.143281, BC Loss: 20839.021484, IC Loss: 3844.903076, LR: 0.00011098\n",
      "Epoch 1000, Total Loss: 64632.468750, PDE Loss: 0.285999, BC Loss: 19694.912109, IC Loss: 3557.069092, LR: 0.00011098\n",
      "Epoch 1500, Total Loss: 61075.535156, PDE Loss: 1.174454, BC Loss: 18683.814453, IC Loss: 3302.967773, LR: 0.00011098\n",
      "Epoch 2000, Total Loss: 57671.195312, PDE Loss: 5.162680, BC Loss: 17729.554688, IC Loss: 3047.814697, LR: 0.00011098\n",
      "Epoch 2500, Total Loss: 54395.093750, PDE Loss: 6.074665, BC Loss: 16807.128906, IC Loss: 2806.691406, LR: 0.00011098\n",
      "Epoch 3000, Total Loss: 51231.179688, PDE Loss: 5.455403, BC Loss: 15914.888672, IC Loss: 2575.525879, LR: 0.00011098\n",
      "Epoch 3500, Total Loss: 48194.058594, PDE Loss: 5.996443, BC Loss: 15052.503906, IC Loss: 2357.884766, LR: 0.00011098\n",
      "Epoch 4000, Total Loss: 45290.957031, PDE Loss: 8.643895, BC Loss: 14220.733398, IC Loss: 2154.945557, LR: 0.00011098\n",
      "Epoch 4500, Total Loss: 42521.039062, PDE Loss: 13.033656, BC Loss: 13418.719727, IC Loss: 1967.287964, LR: 0.00011098\n",
      "Epoch 5000, Total Loss: 39873.246094, PDE Loss: 16.887272, BC Loss: 12644.944336, IC Loss: 1793.711060, LR: 0.00011098\n",
      "Epoch 5500, Total Loss: 37339.511719, PDE Loss: 19.953197, BC Loss: 11898.075195, IC Loss: 1632.974487, LR: 0.00011098\n",
      "Epoch 6000, Total Loss: 34911.519531, PDE Loss: 22.299023, BC Loss: 11177.089844, IC Loss: 1483.388428, LR: 0.00011098\n",
      "Epoch 6500, Total Loss: 32581.226562, PDE Loss: 23.458500, BC Loss: 10481.042969, IC Loss: 1343.493774, LR: 0.00011098\n",
      "Epoch 7000, Total Loss: 30346.410156, PDE Loss: 22.966240, BC Loss: 9809.258789, IC Loss: 1213.345825, LR: 0.00011098\n",
      "Epoch 7500, Total Loss: 28205.609375, PDE Loss: 21.139849, BC Loss: 9161.568359, IC Loss: 1092.523193, LR: 0.00011098\n",
      "Epoch 8000, Total Loss: 26155.921875, PDE Loss: 18.545883, BC Loss: 8537.671875, IC Loss: 980.176331, LR: 0.00011098\n",
      "Epoch 8500, Total Loss: 24195.890625, PDE Loss: 15.262419, BC Loss: 7937.412109, IC Loss: 875.968750, LR: 0.00011098\n",
      "Epoch 9000, Total Loss: 22324.820312, PDE Loss: 11.563967, BC Loss: 7360.696289, IC Loss: 779.659668, LR: 0.00011098\n",
      "Epoch 9500, Total Loss: 20542.714844, PDE Loss: 8.235001, BC Loss: 6807.483398, IC Loss: 690.976257, LR: 0.00011098\n",
      "Epoch 9999, Total Loss: 18852.539062, PDE Loss: 6.022193, BC Loss: 6278.676758, IC Loss: 609.791626, LR: 0.00011098\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>██▇▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>bc_loss_norm_factor</td><td>▁▁▁▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇█</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>final_bc_loss</td><td>▁</td></tr><tr><td>final_ic_loss</td><td>▁</td></tr><tr><td>final_pde_loss</td><td>▁</td></tr><tr><td>final_total_loss</td><td>▁</td></tr><tr><td>ic_loss</td><td>█▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>ic_loss_norm_factor</td><td>█████▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▃▂▂▂▂▂▂▂▂▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>pde_loss</td><td>▁▁▁▁▁▁▁▃▃▃▃▄▄▄▄▆▆▆▆▆▇▇▇▇▇██████▇▇▇▇▆▆▅▅▄</td></tr><tr><td>total_loss</td><td>██▇▇▇▇▇▆▆▆▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>6278.67676</td></tr><tr><td>bc_loss_norm_factor</td><td>0.33304</td></tr><tr><td>epoch</td><td>9999</td></tr><tr><td>final_bc_loss</td><td>6278.67676</td></tr><tr><td>final_ic_loss</td><td>609.79163</td></tr><tr><td>final_pde_loss</td><td>6.02219</td></tr><tr><td>final_total_loss</td><td>18852.53906</td></tr><tr><td>ic_loss</td><td>609.79163</td></tr><tr><td>ic_loss_norm_factor</td><td>0.03235</td></tr><tr><td>learning_rate</td><td>0.00011</td></tr><tr><td>pde_loss</td><td>6.02219</td></tr><tr><td>total_loss</td><td>18852.53906</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">electric-sweep-4</strong> at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/plkmh4l3' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/plkmh4l3</a><br> View project at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250715_120850-plkmh4l3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 7vju75t1 with config:\n",
      "wandb: \tbc_weight_scale: 1.8535255130150383\n",
      "wandb: \tic_weight_scale: 0.1677028055187026\n",
      "wandb: \tinitial_lr: 0.0005076329728318507\n",
      "wandb: \tlr_factor: 0.4638932037250979\n",
      "wandb: \tlr_patience: 453\n",
      "wandb: \tpde_weight_scale: 3.547444002423858\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tobys\\Desktop\\STAR\\dev_notebooks\\black_scholes\\wandb\\run-20250715_120936-7vju75t1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/7vju75t1' target=\"_blank\">fluent-sweep-5</a></strong> to <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/sweeps/y2ttpnwf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/7vju75t1' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/7vju75t1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run with Weights: PDE=3.55e+00, BC=1.85e+00, IC=1.68e-01, Initial LR=5.08e-04, Patience=453, Factor=0.46\n",
      "Epoch 0, Total Loss: 43880.218750, PDE Loss: 0.000283, BC Loss: 23265.033203, IC Loss: 4519.233398, LR: 0.00050763\n",
      "Epoch 500, Total Loss: 32551.050781, PDE Loss: 0.836261, BC Loss: 17287.849609, IC Loss: 3008.977783, LR: 0.00050763\n",
      "Epoch 1000, Total Loss: 25287.523438, PDE Loss: 1.763270, BC Loss: 13446.247070, IC Loss: 2136.546631, LR: 0.00050763\n",
      "Epoch 1500, Total Loss: 19290.335938, PDE Loss: 3.230553, BC Loss: 10274.416992, IC Loss: 1401.173828, LR: 0.00050763\n",
      "Epoch 2000, Total Loss: 14372.528320, PDE Loss: 3.335153, BC Loss: 7666.928711, IC Loss: 893.541809, LR: 0.00050763\n",
      "Epoch 2500, Total Loss: 10391.081055, PDE Loss: 2.732703, BC Loss: 5552.626465, IC Loss: 533.398560, LR: 0.00050763\n",
      "Epoch 3000, Total Loss: 7234.910156, PDE Loss: 2.403996, BC Loss: 3871.538086, IC Loss: 300.458893, LR: 0.00050763\n",
      "Epoch 3500, Total Loss: 4802.704102, PDE Loss: 2.001111, BC Loss: 2572.833496, IC Loss: 159.763779, LR: 0.00050763\n",
      "Epoch 4000, Total Loss: 2999.299072, PDE Loss: 1.543749, BC Loss: 1608.111084, IC Loss: 78.399063, LR: 0.00050763\n",
      "Epoch 4500, Total Loss: 1730.662842, PDE Loss: 1.337219, BC Loss: 927.877258, IC Loss: 36.225441, LR: 0.00050763\n",
      "Epoch 5000, Total Loss: 900.905334, PDE Loss: 1.032804, BC Loss: 482.573761, IC Loss: 16.569550, LR: 0.00050763\n",
      "Epoch 5500, Total Loss: 409.866089, PDE Loss: 0.774115, BC Loss: 218.843063, IC Loss: 8.877447, LR: 0.00050763\n",
      "Epoch 6000, Total Loss: 156.972229, PDE Loss: 0.504907, BC Loss: 83.212975, IC Loss: 5.627466, LR: 0.00050763\n",
      "Epoch 6500, Total Loss: 49.359661, PDE Loss: 0.271060, BC Loss: 25.645826, IC Loss: 5.145380, LR: 0.00050763\n",
      "Epoch 7000, Total Loss: 13.996243, PDE Loss: 0.149476, BC Loss: 6.930732, IC Loss: 3.695205, LR: 0.00050763\n",
      "Epoch 7500, Total Loss: 5.032819, PDE Loss: 0.049992, BC Loss: 2.311171, IC Loss: 3.408767, LR: 0.00050763\n",
      "Epoch 8000, Total Loss: 2.816774, PDE Loss: 0.034087, BC Loss: 1.179310, IC Loss: 3.040918, LR: 0.00050763\n",
      "Epoch 8500, Total Loss: 1.846466, PDE Loss: 0.025663, BC Loss: 0.695079, IC Loss: 2.785170, LR: 0.00050763\n",
      "Epoch 9000, Total Loss: 1.413243, PDE Loss: 0.027652, BC Loss: 0.468174, IC Loss: 2.667663, LR: 0.00050763\n",
      "Epoch 9500, Total Loss: 1.097376, PDE Loss: 0.016236, BC Loss: 0.358676, IC Loss: 2.235878, LR: 0.00050763\n",
      "Epoch 9999, Total Loss: 0.899154, PDE Loss: 0.012834, BC Loss: 0.271738, IC Loss: 2.086747, LR: 0.00050763\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>█▇▆▆▅▅▄▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>bc_loss_norm_factor</td><td>████████████████████████▇▆▆▆▆▅▄▄▄▃▃▂▂▂▁▂</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>final_bc_loss</td><td>▁</td></tr><tr><td>final_ic_loss</td><td>▁</td></tr><tr><td>final_pde_loss</td><td>▁</td></tr><tr><td>final_total_loss</td><td>▁</td></tr><tr><td>ic_loss</td><td>██▇▇▇▅▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ic_loss_norm_factor</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▄▅▆▆▇▇▇████</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>pde_loss</td><td>▁▂▃▃▄▅▆▇▇███▇▇▇▇▆▆▅▄▄▄▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_loss</td><td>█▇▆▅▅▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>0.27174</td></tr><tr><td>bc_loss_norm_factor</td><td>0.30221</td></tr><tr><td>epoch</td><td>9999</td></tr><tr><td>final_bc_loss</td><td>0.27174</td></tr><tr><td>final_ic_loss</td><td>2.08675</td></tr><tr><td>final_pde_loss</td><td>0.01283</td></tr><tr><td>final_total_loss</td><td>0.89915</td></tr><tr><td>ic_loss</td><td>2.08675</td></tr><tr><td>ic_loss_norm_factor</td><td>2.32079</td></tr><tr><td>learning_rate</td><td>0.00051</td></tr><tr><td>pde_loss</td><td>0.01283</td></tr><tr><td>total_loss</td><td>0.89915</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fluent-sweep-5</strong> at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/7vju75t1' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep/runs/7vju75t1</a><br> View project at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Loss_Weight_Sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250715_120936-7vju75t1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#wandb.agent('y2ttpnwf', function=train_pinn_sweep, count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1e993f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: zdv6nzua\n",
      "Sweep URL: https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua\n",
      "Sweep ID: zdv6nzua\n",
      "Run the following command in your terminal to start sweep agents:\n",
      "wandb agent zdv6nzua\n",
      "\n",
      "Alternatively, to run agents directly in this notebook (for local testing):\n",
      "wandb.agent('zdv6nzua', function=train_pinn_sweep, count=6)\n",
      " zdv6nzua\n",
      "Sweep URL: https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua\n",
      "Sweep ID: zdv6nzua\n",
      "Run the following command in your terminal to start sweep agents:\n",
      "wandb agent zdv6nzua\n",
      "\n",
      "Alternatively, to run agents directly in this notebook (for local testing):\n",
      "wandb.agent('zdv6nzua', function=train_pinn_sweep, count=6)\n"
     ]
    }
   ],
   "source": [
    "# Sweep Configuration\n",
    "sweep_config = {\n",
    "    'method': 'random',  # or 'grid' or 'bayes'\n",
    "    'metric': {\n",
    "        'name': 'final_total_loss',\n",
    "        'goal': 'minimize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'hidden_layers': {\n",
    "            'values': [4, 6, 8]  # Number of hidden layers\n",
    "        },\n",
    "        'neurons_per_layer': {\n",
    "            'values': [32, 64, 128, 256]  # Number of neurons per layer\n",
    "        },\n",
    "        'activation': {\n",
    "            'values': ['tanh', 'relu', 'silu']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Weight initialization utility\n",
    "def initialize_weights(model, method='xavier'):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            # Always use xavier\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "# Training function for sweep\n",
    "def train_pinn_sweep():\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "\n",
    "    # Activation function map\n",
    "    activation_map = {\n",
    "        'tanh': nn.Tanh(),\n",
    "        'relu': nn.ReLU(),\n",
    "        'silu': nn.SiLU()\n",
    "    }\n",
    "    activation_fn = activation_map.get(config.activation, nn.Tanh())\n",
    "\n",
    "    # Model setup\n",
    "    model = blackScholesPINN(\n",
    "        hidden_layers=config.hidden_layers,\n",
    "        neurons_per_layer=config.neurons_per_layer,\n",
    "        activation_fn=activation_fn\n",
    "    )\n",
    "    initialize_weights(model, method='xavier')\n",
    "\n",
    "    # Fixed hyperparameters\n",
    "    initial_lr = 0.005\n",
    "    pde_weight = 3.547\n",
    "    bc_weight = 1.854\n",
    "    ic_weight = 0.168\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr)\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=300,\n",
    "        min_lr=1e-7,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    epochs = 5000\n",
    "\n",
    "    print(f\"Starting run with Layers={config.hidden_layers}, Neurons={config.neurons_per_layer}, \"\n",
    "          f\"Init=xavier, Activation={config.activation}, LR={initial_lr}\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        V = model(torch.cat((S, t), dim=1))\n",
    "        pde_l = pde_loss(model, S, t)\n",
    "        bc_l = boundary_loss(model, t)\n",
    "        ic_l = initial_loss(model, S)\n",
    "\n",
    "        total_loss = (pde_weight * pde_l) + (bc_weight * bc_l) + (ic_weight * ic_l)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(total_loss)\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"total_loss\": total_loss.item(),\n",
    "            \"pde_loss\": pde_l.item(),\n",
    "            \"bc_loss\": bc_l.item(),\n",
    "            \"ic_loss\": ic_l.item(),\n",
    "            \"learning_rate\": current_lr\n",
    "        })\n",
    "\n",
    "        if epoch % 500 == 0 or epoch == epochs - 1:\n",
    "            print(f'Epoch {epoch}, Total Loss: {total_loss.item():.6f}, '\n",
    "                  f'PDE Loss: {pde_l.item():.6f}, BC Loss: {bc_l.item():.6f}, '\n",
    "                  f'IC Loss: {ic_l.item():.6f}, LR: {current_lr:.8f}')\n",
    "\n",
    "    wandb.log({\n",
    "        \"final_total_loss\": total_loss.item(),\n",
    "        \"final_pde_loss\": pde_l.item(),\n",
    "        \"final_bc_loss\": bc_l.item(),\n",
    "        \"final_ic_loss\": ic_l.item()\n",
    "    })\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "# --- Initialize and run the Sweep ---\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"PINN_Architecture_Sweep\")\n",
    "\n",
    "print(f\"Sweep ID: {sweep_id}\")\n",
    "print(\"Run the following command in your terminal to start sweep agents:\")\n",
    "print(f\"wandb agent {sweep_id}\")\n",
    "print(\"\\nAlternatively, to run agents directly in this notebook (for local testing):\")\n",
    "print(f\"wandb.agent('{sweep_id}', function=train_pinn_sweep, count=6)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a26b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: xab7wth8 with config:\n",
      "wandb: \tactivation: tanh\n",
      "wandb: \thidden_layers: 6\n",
      "wandb: \tneurons_per_layer: 256\n",
      "wandb: \tactivation: tanh\n",
      "wandb: \thidden_layers: 6\n",
      "wandb: \tneurons_per_layer: 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tobys\\Desktop\\STAR\\dev_notebooks\\black_scholes\\wandb\\run-20250715_134152-xab7wth8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/xab7wth8' target=\"_blank\">cool-sweep-1</a></strong> to <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/xab7wth8' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/xab7wth8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run with Layers=6, Neurons=256, Init=xavier, Activation=tanh, LR=0.005\n",
      "\n",
      "Epoch 0, Total Loss: 43796.589844, PDE Loss: 0.000904, BC Loss: 23214.472656, IC Loss: 4505.666016, LR: 0.00500000\n",
      "Epoch 0, Total Loss: 43796.589844, PDE Loss: 0.000904, BC Loss: 23214.472656, IC Loss: 4505.666016, LR: 0.00500000\n",
      "Epoch 500, Total Loss: 22173.500000, PDE Loss: 13.953033, BC Loss: 11628.466797, IC Loss: 3362.078857, LR: 0.00250000\n",
      "Epoch 500, Total Loss: 22173.500000, PDE Loss: 13.953033, BC Loss: 11628.466797, IC Loss: 3362.078857, LR: 0.00250000\n",
      "Epoch 1000, Total Loss: 22173.492188, PDE Loss: 13.953033, BC Loss: 11628.462891, IC Loss: 3362.078857, LR: 0.00062500\n",
      "Epoch 1000, Total Loss: 22173.492188, PDE Loss: 13.953033, BC Loss: 11628.462891, IC Loss: 3362.078857, LR: 0.00062500\n",
      "Epoch 1500, Total Loss: 3029.115234, PDE Loss: 38.952511, BC Loss: 758.805603, IC Loss: 8834.077148, LR: 0.00062500\n",
      "Epoch 1500, Total Loss: 3029.115234, PDE Loss: 38.952511, BC Loss: 758.805603, IC Loss: 8834.077148, LR: 0.00062500\n",
      "Epoch 2000, Total Loss: 2372.312256, PDE Loss: 50.947659, BC Loss: 93.395699, IC Loss: 12014.555664, LR: 0.00062500\n",
      "Epoch 2000, Total Loss: 2372.312256, PDE Loss: 50.947659, BC Loss: 93.395699, IC Loss: 12014.555664, LR: 0.00062500\n",
      "Epoch 2500, Total Loss: 2372.310059, PDE Loss: 50.972466, BC Loss: 92.731689, IC Loss: 12021.346680, LR: 0.00015625\n",
      "Epoch 2500, Total Loss: 2372.310059, PDE Loss: 50.972466, BC Loss: 92.731689, IC Loss: 12021.346680, LR: 0.00015625\n",
      "Epoch 3000, Total Loss: 2372.310059, PDE Loss: 50.972466, BC Loss: 92.731682, IC Loss: 12021.346680, LR: 0.00007813\n",
      "Epoch 3000, Total Loss: 2372.310059, PDE Loss: 50.972466, BC Loss: 92.731682, IC Loss: 12021.346680, LR: 0.00007813\n",
      "Epoch 3500, Total Loss: 2372.310059, PDE Loss: 50.972466, BC Loss: 92.731682, IC Loss: 12021.346680, LR: 0.00001953\n",
      "Epoch 3500, Total Loss: 2372.310059, PDE Loss: 50.972466, BC Loss: 92.731682, IC Loss: 12021.346680, LR: 0.00001953\n",
      "Epoch 4000, Total Loss: 2372.310059, PDE Loss: 50.972466, BC Loss: 92.731682, IC Loss: 12021.346680, LR: 0.00000488\n",
      "Epoch 4000, Total Loss: 2372.310059, PDE Loss: 50.972466, BC Loss: 92.731682, IC Loss: 12021.346680, LR: 0.00000488\n",
      "Epoch 4500, Total Loss: 2372.310059, PDE Loss: 50.972466, BC Loss: 92.731682, IC Loss: 12021.346680, LR: 0.00000244\n",
      "Epoch 4500, Total Loss: 2372.310059, PDE Loss: 50.972466, BC Loss: 92.731682, IC Loss: 12021.346680, LR: 0.00000244\n",
      "Epoch 4999, Total Loss: 2372.310059, PDE Loss: 50.972466, BC Loss: 92.731682, IC Loss: 12021.346680, LR: 0.00000061\n",
      "Epoch 4999, Total Loss: 2372.310059, PDE Loss: 50.972466, BC Loss: 92.731682, IC Loss: 12021.346680, LR: 0.00000061\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>██████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>final_bc_loss</td><td>▁</td></tr><tr><td>final_ic_loss</td><td>▁</td></tr><tr><td>final_pde_loss</td><td>▁</td></tr><tr><td>final_total_loss</td><td>▁</td></tr><tr><td>ic_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▃▄▅██████████████████████████</td></tr><tr><td>learning_rate</td><td>██▄▄▄▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>pde_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▂▇█████████████████████████</td></tr><tr><td>total_loss</td><td>██████▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>92.73168</td></tr><tr><td>epoch</td><td>4999</td></tr><tr><td>final_bc_loss</td><td>92.73168</td></tr><tr><td>final_ic_loss</td><td>12021.34668</td></tr><tr><td>final_pde_loss</td><td>50.97247</td></tr><tr><td>final_total_loss</td><td>2372.31006</td></tr><tr><td>ic_loss</td><td>12021.34668</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>pde_loss</td><td>50.97247</td></tr><tr><td>total_loss</td><td>2372.31006</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cool-sweep-1</strong> at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/xab7wth8' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/xab7wth8</a><br> View project at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250715_134152-xab7wth8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 56651imt with config:\n",
      "wandb: \tactivation: tanh\n",
      "wandb: \thidden_layers: 8\n",
      "wandb: \tneurons_per_layer: 64\n",
      "wandb: \tactivation: tanh\n",
      "wandb: \thidden_layers: 8\n",
      "wandb: \tneurons_per_layer: 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tobys\\Desktop\\STAR\\dev_notebooks\\black_scholes\\wandb\\run-20250715_134406-56651imt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/56651imt' target=\"_blank\">expert-sweep-2</a></strong> to <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/56651imt' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/56651imt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run with Layers=8, Neurons=64, Init=xavier, Activation=tanh, LR=0.005\n",
      "\n",
      "Epoch 0, Total Loss: 44184.976562, PDE Loss: 0.002020, BC Loss: 23418.617188, IC Loss: 4564.586426, LR: 0.00500000\n",
      "Epoch 0, Total Loss: 44184.976562, PDE Loss: 0.002020, BC Loss: 23418.617188, IC Loss: 4564.586426, LR: 0.00500000\n",
      "Epoch 500, Total Loss: 21774.291016, PDE Loss: 12.588323, BC Loss: 11434.619141, IC Loss: 3153.916992, LR: 0.00500000\n",
      "Epoch 500, Total Loss: 21774.291016, PDE Loss: 12.588323, BC Loss: 11434.619141, IC Loss: 3153.916992, LR: 0.00500000\n",
      "Epoch 1000, Total Loss: 28643.285156, PDE Loss: 37.125053, BC Loss: 14618.945312, IC Loss: 8381.432617, LR: 0.00500000\n",
      "Epoch 1000, Total Loss: 28643.285156, PDE Loss: 37.125053, BC Loss: 14618.945312, IC Loss: 8381.432617, LR: 0.00500000\n",
      "Epoch 1500, Total Loss: 17923.925781, PDE Loss: 16.849136, BC Loss: 9286.174805, IC Loss: 3854.721680, LR: 0.00250000\n",
      "Epoch 1500, Total Loss: 17923.925781, PDE Loss: 16.849136, BC Loss: 9286.174805, IC Loss: 3854.721680, LR: 0.00250000\n",
      "Epoch 2000, Total Loss: 16781.753906, PDE Loss: 18.156557, BC Loss: 8645.751953, IC Loss: 4096.008789, LR: 0.00062500\n",
      "Epoch 2000, Total Loss: 16781.753906, PDE Loss: 18.156557, BC Loss: 8645.751953, IC Loss: 4096.008789, LR: 0.00062500\n",
      "Epoch 2500, Total Loss: 16499.724609, PDE Loss: 18.416349, BC Loss: 8488.679688, IC Loss: 4145.174316, LR: 0.00015625\n",
      "Epoch 2500, Total Loss: 16499.724609, PDE Loss: 18.416349, BC Loss: 8488.679688, IC Loss: 4145.174316, LR: 0.00015625\n",
      "Epoch 3000, Total Loss: 16424.166016, PDE Loss: 18.482204, BC Loss: 8446.664062, IC Loss: 4157.700195, LR: 0.00007813\n",
      "Epoch 3000, Total Loss: 16424.166016, PDE Loss: 18.482204, BC Loss: 8446.664062, IC Loss: 4157.700195, LR: 0.00007813\n",
      "Epoch 3500, Total Loss: 16398.708984, PDE Loss: 18.502913, BC Loss: 8432.537109, IC Loss: 4161.643066, LR: 0.00001953\n",
      "Epoch 3500, Total Loss: 16398.708984, PDE Loss: 18.502913, BC Loss: 8432.537109, IC Loss: 4161.643066, LR: 0.00001953\n",
      "Epoch 4000, Total Loss: 16390.621094, PDE Loss: 18.508696, BC Loss: 8428.063477, IC Loss: 4162.745117, LR: 0.00000977\n",
      "Epoch 4000, Total Loss: 16390.621094, PDE Loss: 18.508696, BC Loss: 8428.063477, IC Loss: 4162.745117, LR: 0.00000977\n",
      "Epoch 4500, Total Loss: 16388.343750, PDE Loss: 18.509857, BC Loss: 8426.812500, IC Loss: 4162.965820, LR: 0.00000244\n",
      "Epoch 4500, Total Loss: 16388.343750, PDE Loss: 18.509857, BC Loss: 8426.812500, IC Loss: 4162.965820, LR: 0.00000244\n",
      "Epoch 4999, Total Loss: 16387.519531, PDE Loss: 18.510508, BC Loss: 8426.355469, IC Loss: 4163.090820, LR: 0.00000061\n",
      "Epoch 4999, Total Loss: 16387.519531, PDE Loss: 18.510508, BC Loss: 8426.355469, IC Loss: 4163.090820, LR: 0.00000061\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>█▅▅▅▅▃▂▁▁▁▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>final_bc_loss</td><td>▁</td></tr><tr><td>final_ic_loss</td><td>▁</td></tr><tr><td>final_pde_loss</td><td>▁</td></tr><tr><td>final_total_loss</td><td>▁</td></tr><tr><td>ic_loss</td><td>▂▁▁▁▁▂▂▂▂▃▄▅█▄▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>learning_rate</td><td>██████████▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>pde_loss</td><td>▁▁▁▃▄▄▄▄▄▆█▅▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>total_loss</td><td>█▇▇▇▇▆▆▆▅▆▁▇▇▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>8426.35547</td></tr><tr><td>epoch</td><td>4999</td></tr><tr><td>final_bc_loss</td><td>8426.35547</td></tr><tr><td>final_ic_loss</td><td>4163.09082</td></tr><tr><td>final_pde_loss</td><td>18.51051</td></tr><tr><td>final_total_loss</td><td>16387.51953</td></tr><tr><td>ic_loss</td><td>4163.09082</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>pde_loss</td><td>18.51051</td></tr><tr><td>total_loss</td><td>16387.51953</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">expert-sweep-2</strong> at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/56651imt' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/56651imt</a><br> View project at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250715_134406-56651imt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: t50evabp with config:\n",
      "wandb: \tactivation: tanh\n",
      "wandb: \thidden_layers: 4\n",
      "wandb: \tneurons_per_layer: 128\n",
      "wandb: \tactivation: tanh\n",
      "wandb: \thidden_layers: 4\n",
      "wandb: \tneurons_per_layer: 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tobys\\Desktop\\STAR\\dev_notebooks\\black_scholes\\wandb\\run-20250715_134507-t50evabp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/t50evabp' target=\"_blank\">autumn-sweep-3</a></strong> to <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/t50evabp' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/t50evabp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run with Layers=4, Neurons=128, Init=xavier, Activation=tanh, LR=0.005\n",
      "Epoch 0, Total Loss: 44128.250000, PDE Loss: 0.002401, BC Loss: 23388.615234, IC Loss: 4558.042480, LR: 0.00500000\n",
      "Epoch 0, Total Loss: 44128.250000, PDE Loss: 0.002401, BC Loss: 23388.615234, IC Loss: 4558.042480, LR: 0.00500000\n",
      "\n",
      "Epoch 500, Total Loss: 2373.088135, PDE Loss: 50.546951, BC Loss: 104.730309, IC Loss: 11902.548828, LR: 0.00500000\n",
      "Epoch 500, Total Loss: 2373.088135, PDE Loss: 50.546951, BC Loss: 104.730309, IC Loss: 11902.548828, LR: 0.00500000\n",
      "Epoch 1000, Total Loss: 2372.286377, PDE Loss: 50.968826, BC Loss: 92.793869, IC Loss: 12020.595703, LR: 0.00125000\n",
      "Epoch 1000, Total Loss: 2372.286377, PDE Loss: 50.968826, BC Loss: 92.793869, IC Loss: 12020.595703, LR: 0.00125000\n",
      "Epoch 1500, Total Loss: 2371.680176, PDE Loss: 50.622578, BC Loss: 99.780281, IC Loss: 11947.197266, LR: 0.00062500\n",
      "Epoch 1500, Total Loss: 2371.680176, PDE Loss: 50.622578, BC Loss: 99.780281, IC Loss: 11947.197266, LR: 0.00062500\n",
      "Epoch 2000, Total Loss: 426.213623, PDE Loss: 30.610558, BC Loss: 81.471626, IC Loss: 991.604797, LR: 0.00031250\n",
      "Epoch 2000, Total Loss: 426.213623, PDE Loss: 30.610558, BC Loss: 81.471626, IC Loss: 991.604797, LR: 0.00031250\n",
      "Epoch 2500, Total Loss: 112.938141, PDE Loss: 9.840667, BC Loss: 25.776003, IC Loss: 180.027267, LR: 0.00031250\n",
      "Epoch 2500, Total Loss: 112.938141, PDE Loss: 9.840667, BC Loss: 25.776003, IC Loss: 180.027267, LR: 0.00031250\n",
      "Epoch 3000, Total Loss: 53.639198, PDE Loss: 4.150098, BC Loss: 13.196720, IC Loss: 86.024315, LR: 0.00031250\n",
      "Epoch 3000, Total Loss: 53.639198, PDE Loss: 4.150098, BC Loss: 13.196720, IC Loss: 86.024315, LR: 0.00031250\n",
      "Epoch 3500, Total Loss: 34.154530, PDE Loss: 2.073233, BC Loss: 11.608776, IC Loss: 31.417250, LR: 0.00031250\n",
      "Epoch 3500, Total Loss: 34.154530, PDE Loss: 2.073233, BC Loss: 11.608776, IC Loss: 31.417250, LR: 0.00031250\n",
      "Epoch 4000, Total Loss: 22.187666, PDE Loss: 0.712692, BC Loss: 7.971998, IC Loss: 29.045612, LR: 0.00031250\n",
      "Epoch 4000, Total Loss: 22.187666, PDE Loss: 0.712692, BC Loss: 7.971998, IC Loss: 29.045612, LR: 0.00031250\n",
      "Epoch 4500, Total Loss: 20.547192, PDE Loss: 1.377074, BC Loss: 6.053736, IC Loss: 26.423119, LR: 0.00031250\n",
      "Epoch 4500, Total Loss: 20.547192, PDE Loss: 1.377074, BC Loss: 6.053736, IC Loss: 26.423119, LR: 0.00031250\n",
      "Epoch 4999, Total Loss: 9.685019, PDE Loss: 0.348947, BC Loss: 1.743736, IC Loss: 31.038197, LR: 0.00031250\n",
      "Epoch 4999, Total Loss: 9.685019, PDE Loss: 0.348947, BC Loss: 1.743736, IC Loss: 31.038197, LR: 0.00031250\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>█▆▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇█</td></tr><tr><td>final_bc_loss</td><td>▁</td></tr><tr><td>final_ic_loss</td><td>▁</td></tr><tr><td>final_pde_loss</td><td>▁</td></tr><tr><td>final_total_loss</td><td>▁</td></tr><tr><td>ic_loss</td><td>███████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>████████▄▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>pde_loss</td><td>▁██████████████▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_loss</td><td>███▆▆▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>1.74374</td></tr><tr><td>epoch</td><td>4999</td></tr><tr><td>final_bc_loss</td><td>1.74374</td></tr><tr><td>final_ic_loss</td><td>31.0382</td></tr><tr><td>final_pde_loss</td><td>0.34895</td></tr><tr><td>final_total_loss</td><td>9.68502</td></tr><tr><td>ic_loss</td><td>31.0382</td></tr><tr><td>learning_rate</td><td>0.00031</td></tr><tr><td>pde_loss</td><td>0.34895</td></tr><tr><td>total_loss</td><td>9.68502</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">autumn-sweep-3</strong> at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/t50evabp' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/t50evabp</a><br> View project at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250715_134507-t50evabp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: jrlhe53y with config:\n",
      "wandb: \tactivation: tanh\n",
      "wandb: \thidden_layers: 6\n",
      "wandb: \tneurons_per_layer: 256\n",
      "wandb: \tactivation: tanh\n",
      "wandb: \thidden_layers: 6\n",
      "wandb: \tneurons_per_layer: 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for wandb.init()..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tobys\\Desktop\\STAR\\dev_notebooks\\black_scholes\\wandb\\run-20250715_134559-jrlhe53y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/jrlhe53y' target=\"_blank\">likely-sweep-4</a></strong> to <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/jrlhe53y' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/jrlhe53y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run with Layers=6, Neurons=256, Init=xavier, Activation=tanh, LR=0.005\n",
      "\n",
      "Epoch 0, Total Loss: 43511.875000, PDE Loss: 0.001384, BC Loss: 23065.126953, IC Loss: 4459.077637, LR: 0.00500000\n",
      "Epoch 0, Total Loss: 43511.875000, PDE Loss: 0.001384, BC Loss: 23065.126953, IC Loss: 4459.077637, LR: 0.00500000\n",
      "Epoch 500, Total Loss: 2597.024414, PDE Loss: 43.831562, BC Loss: 401.581848, IC Loss: 10101.317383, LR: 0.00500000\n",
      "Epoch 500, Total Loss: 2597.024414, PDE Loss: 43.831562, BC Loss: 401.581848, IC Loss: 10101.317383, LR: 0.00500000\n",
      "Epoch 1000, Total Loss: 2372.309814, PDE Loss: 50.972885, BC Loss: 92.719742, IC Loss: 12021.467773, LR: 0.00250000\n",
      "Epoch 1000, Total Loss: 2372.309814, PDE Loss: 50.972885, BC Loss: 92.719742, IC Loss: 12021.467773, LR: 0.00250000\n",
      "Epoch 1500, Total Loss: 2372.309570, PDE Loss: 50.972885, BC Loss: 92.719444, IC Loss: 12021.469727, LR: 0.00062500\n",
      "Epoch 1500, Total Loss: 2372.309570, PDE Loss: 50.972885, BC Loss: 92.719444, IC Loss: 12021.469727, LR: 0.00062500\n",
      "Epoch 2000, Total Loss: 2372.309814, PDE Loss: 50.972885, BC Loss: 92.719734, IC Loss: 12021.467773, LR: 0.00031250\n",
      "Epoch 2000, Total Loss: 2372.309814, PDE Loss: 50.972885, BC Loss: 92.719734, IC Loss: 12021.467773, LR: 0.00031250\n",
      "Epoch 2500, Total Loss: 2372.309814, PDE Loss: 50.972885, BC Loss: 92.719734, IC Loss: 12021.467773, LR: 0.00007813\n",
      "Epoch 2500, Total Loss: 2372.309814, PDE Loss: 50.972885, BC Loss: 92.719734, IC Loss: 12021.467773, LR: 0.00007813\n",
      "Epoch 3000, Total Loss: 2372.309814, PDE Loss: 50.972862, BC Loss: 92.720024, IC Loss: 12021.464844, LR: 0.00001953\n",
      "Epoch 3000, Total Loss: 2372.309814, PDE Loss: 50.972862, BC Loss: 92.720024, IC Loss: 12021.464844, LR: 0.00001953\n",
      "Epoch 3500, Total Loss: 2372.309814, PDE Loss: 50.972862, BC Loss: 92.720024, IC Loss: 12021.464844, LR: 0.00000977\n",
      "Epoch 3500, Total Loss: 2372.309814, PDE Loss: 50.972862, BC Loss: 92.720024, IC Loss: 12021.464844, LR: 0.00000977\n",
      "Epoch 4000, Total Loss: 2372.309814, PDE Loss: 50.972862, BC Loss: 92.720024, IC Loss: 12021.464844, LR: 0.00000244\n",
      "Epoch 4000, Total Loss: 2372.309814, PDE Loss: 50.972862, BC Loss: 92.720024, IC Loss: 12021.464844, LR: 0.00000244\n",
      "Epoch 4500, Total Loss: 2372.309814, PDE Loss: 50.972862, BC Loss: 92.720024, IC Loss: 12021.464844, LR: 0.00000061\n",
      "Epoch 4500, Total Loss: 2372.309814, PDE Loss: 50.972862, BC Loss: 92.720024, IC Loss: 12021.464844, LR: 0.00000061\n",
      "Epoch 4999, Total Loss: 2372.309814, PDE Loss: 50.972862, BC Loss: 92.720024, IC Loss: 12021.464844, LR: 0.00000031\n",
      "Epoch 4999, Total Loss: 2372.309814, PDE Loss: 50.972862, BC Loss: 92.720024, IC Loss: 12021.464844, LR: 0.00000031\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>█▇▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>final_bc_loss</td><td>▁</td></tr><tr><td>final_ic_loss</td><td>▁</td></tr><tr><td>final_pde_loss</td><td>▁</td></tr><tr><td>final_total_loss</td><td>▁</td></tr><tr><td>ic_loss</td><td>▁▁▁▁▃███████████████████████████████████</td></tr><tr><td>learning_rate</td><td>█████████▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>pde_loss</td><td>▁▂▂█████████████████████████████████████</td></tr><tr><td>total_loss</td><td>███▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>92.72002</td></tr><tr><td>epoch</td><td>4999</td></tr><tr><td>final_bc_loss</td><td>92.72002</td></tr><tr><td>final_ic_loss</td><td>12021.46484</td></tr><tr><td>final_pde_loss</td><td>50.97286</td></tr><tr><td>final_total_loss</td><td>2372.30981</td></tr><tr><td>ic_loss</td><td>12021.46484</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>pde_loss</td><td>50.97286</td></tr><tr><td>total_loss</td><td>2372.30981</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-sweep-4</strong> at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/jrlhe53y' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/jrlhe53y</a><br> View project at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250715_134559-jrlhe53y\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: k0w5wvce with config:\n",
      "wandb: \tactivation: relu\n",
      "wandb: \thidden_layers: 8\n",
      "wandb: \tneurons_per_layer: 256\n",
      "wandb: \tactivation: relu\n",
      "wandb: \thidden_layers: 8\n",
      "wandb: \tneurons_per_layer: 256\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tobys\\Desktop\\STAR\\dev_notebooks\\black_scholes\\wandb\\run-20250715_134833-k0w5wvce</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/k0w5wvce' target=\"_blank\">dark-sweep-5</a></strong> to <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/k0w5wvce' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/k0w5wvce</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run with Layers=8, Neurons=256, Init=xavier, Activation=relu, LR=0.005\n",
      "\n",
      "Epoch 0, Total Loss: 43725.843750, PDE Loss: 0.000050, BC Loss: 23177.052734, IC Loss: 4497.551758, LR: 0.00500000\n",
      "Epoch 0, Total Loss: 43725.843750, PDE Loss: 0.000050, BC Loss: 23177.052734, IC Loss: 4497.551758, LR: 0.00500000\n",
      "Epoch 500, Total Loss: 276.899811, PDE Loss: 0.056259, BC Loss: 76.752037, IC Loss: 800.011780, LR: 0.00500000\n",
      "Epoch 500, Total Loss: 276.899811, PDE Loss: 0.056259, BC Loss: 76.752037, IC Loss: 800.011780, LR: 0.00500000\n",
      "Epoch 1000, Total Loss: 50.468861, PDE Loss: 0.220326, BC Loss: 1.260478, IC Loss: 281.847839, LR: 0.00500000\n",
      "Epoch 1000, Total Loss: 50.468861, PDE Loss: 0.220326, BC Loss: 1.260478, IC Loss: 281.847839, LR: 0.00500000\n",
      "Epoch 1500, Total Loss: 2.381855, PDE Loss: 0.015470, BC Loss: 0.185243, IC Loss: 11.806792, LR: 0.00500000\n",
      "Epoch 1500, Total Loss: 2.381855, PDE Loss: 0.015470, BC Loss: 0.185243, IC Loss: 11.806792, LR: 0.00500000\n",
      "Epoch 2000, Total Loss: 0.801448, PDE Loss: 0.007381, BC Loss: 0.024929, IC Loss: 4.339567, LR: 0.00500000\n",
      "Epoch 2000, Total Loss: 0.801448, PDE Loss: 0.007381, BC Loss: 0.024929, IC Loss: 4.339567, LR: 0.00500000\n",
      "Epoch 2500, Total Loss: 0.757447, PDE Loss: 0.007119, BC Loss: 0.028667, IC Loss: 4.041948, LR: 0.00250000\n",
      "Epoch 2500, Total Loss: 0.757447, PDE Loss: 0.007119, BC Loss: 0.028667, IC Loss: 4.041948, LR: 0.00250000\n",
      "Epoch 3000, Total Loss: 0.616793, PDE Loss: 0.007314, BC Loss: 0.047755, IC Loss: 2.989959, LR: 0.00250000\n",
      "Epoch 3000, Total Loss: 0.616793, PDE Loss: 0.007314, BC Loss: 0.047755, IC Loss: 2.989959, LR: 0.00250000\n",
      "Epoch 3500, Total Loss: 3.874907, PDE Loss: 0.016438, BC Loss: 1.920308, IC Loss: 1.525891, LR: 0.00250000\n",
      "Epoch 3500, Total Loss: 3.874907, PDE Loss: 0.016438, BC Loss: 1.920308, IC Loss: 1.525891, LR: 0.00250000\n",
      "Epoch 4000, Total Loss: 0.625177, PDE Loss: 0.009092, BC Loss: 0.037776, IC Loss: 3.112447, LR: 0.00062500\n",
      "Epoch 4000, Total Loss: 0.625177, PDE Loss: 0.009092, BC Loss: 0.037776, IC Loss: 3.112447, LR: 0.00062500\n",
      "Epoch 4500, Total Loss: 0.591816, PDE Loss: 0.010095, BC Loss: 0.042301, IC Loss: 2.842761, LR: 0.00031250\n",
      "Epoch 4500, Total Loss: 0.591816, PDE Loss: 0.010095, BC Loss: 0.042301, IC Loss: 2.842761, LR: 0.00031250\n",
      "Epoch 4999, Total Loss: 0.582172, PDE Loss: 0.010653, BC Loss: 0.043876, IC Loss: 2.756199, LR: 0.00015625\n",
      "Epoch 4999, Total Loss: 0.582172, PDE Loss: 0.010653, BC Loss: 0.043876, IC Loss: 2.756199, LR: 0.00015625\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>▁▁▁▁▁▁▂▁▂█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>final_bc_loss</td><td>▁</td></tr><tr><td>final_ic_loss</td><td>▁</td></tr><tr><td>final_pde_loss</td><td>▁</td></tr><tr><td>final_total_loss</td><td>▁</td></tr><tr><td>ic_loss</td><td>▇▇▆▅█▄▅▅▄▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>████████████████████▄▄▄▄▄▄▄▄▄▄▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>pde_loss</td><td>▂▂█▃▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_loss</td><td>██▇▆▅▅▅▂▂▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>0.04388</td></tr><tr><td>epoch</td><td>4999</td></tr><tr><td>final_bc_loss</td><td>0.04388</td></tr><tr><td>final_ic_loss</td><td>2.7562</td></tr><tr><td>final_pde_loss</td><td>0.01065</td></tr><tr><td>final_total_loss</td><td>0.58217</td></tr><tr><td>ic_loss</td><td>2.7562</td></tr><tr><td>learning_rate</td><td>0.00016</td></tr><tr><td>pde_loss</td><td>0.01065</td></tr><tr><td>total_loss</td><td>0.58217</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dark-sweep-5</strong> at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/k0w5wvce' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/k0w5wvce</a><br> View project at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250715_134833-k0w5wvce\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: vzcnpqmo with config:\n",
      "wandb: \tactivation: tanh\n",
      "wandb: \thidden_layers: 4\n",
      "wandb: \tneurons_per_layer: 32\n",
      "wandb: \tactivation: tanh\n",
      "wandb: \thidden_layers: 4\n",
      "wandb: \tneurons_per_layer: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tobys\\Desktop\\STAR\\dev_notebooks\\black_scholes\\wandb\\run-20250715_135123-vzcnpqmo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/vzcnpqmo' target=\"_blank\">royal-sweep-6</a></strong> to <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/sweeps/zdv6nzua</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/vzcnpqmo' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/vzcnpqmo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run with Layers=4, Neurons=32, Init=xavier, Activation=tanh, LR=0.005\n",
      "Epoch 0, Total Loss: 44098.910156, PDE Loss: 0.002913, BC Loss: 23373.384766, IC Loss: 4551.449219, LR: 0.00500000\n",
      "\n",
      "Epoch 0, Total Loss: 44098.910156, PDE Loss: 0.002913, BC Loss: 23373.384766, IC Loss: 4551.449219, LR: 0.00500000\n",
      "Epoch 500, Total Loss: 10799.346680, PDE Loss: 15.180157, BC Loss: 5479.315918, IC Loss: 3493.162598, LR: 0.00500000\n",
      "Epoch 500, Total Loss: 10799.346680, PDE Loss: 15.180157, BC Loss: 5479.315918, IC Loss: 3493.162598, LR: 0.00500000\n",
      "Epoch 1000, Total Loss: 3322.450195, PDE Loss: 35.846451, BC Loss: 1027.083984, IC Loss: 7685.055176, LR: 0.00500000\n",
      "Epoch 1000, Total Loss: 3322.450195, PDE Loss: 35.846451, BC Loss: 1027.083984, IC Loss: 7685.055176, LR: 0.00500000\n",
      "Epoch 1500, Total Loss: 2403.900146, PDE Loss: 47.568905, BC Loss: 205.970200, IC Loss: 11031.575195, LR: 0.00500000\n",
      "Epoch 1500, Total Loss: 2403.900146, PDE Loss: 47.568905, BC Loss: 205.970200, IC Loss: 11031.575195, LR: 0.00500000\n",
      "Epoch 2000, Total Loss: 2346.620117, PDE Loss: 50.028244, BC Loss: 116.836510, IC Loss: 11622.352539, LR: 0.00125000\n",
      "Epoch 2000, Total Loss: 2346.620117, PDE Loss: 50.028244, BC Loss: 116.836510, IC Loss: 11622.352539, LR: 0.00125000\n",
      "Epoch 2500, Total Loss: 2343.825684, PDE Loss: 50.382500, BC Loss: 105.979843, IC Loss: 11718.049805, LR: 0.00062500\n",
      "Epoch 2500, Total Loss: 2343.825684, PDE Loss: 50.382500, BC Loss: 105.979843, IC Loss: 11718.049805, LR: 0.00062500\n",
      "Epoch 3000, Total Loss: 2343.163330, PDE Loss: 50.487991, BC Loss: 102.846344, IC Loss: 11746.459961, LR: 0.00015625\n",
      "Epoch 3000, Total Loss: 2343.163330, PDE Loss: 50.487991, BC Loss: 102.846344, IC Loss: 11746.459961, LR: 0.00015625\n",
      "Epoch 3500, Total Loss: 2342.932861, PDE Loss: 50.525337, BC Loss: 101.744606, IC Loss: 11756.458008, LR: 0.00003906\n",
      "Epoch 3500, Total Loss: 2342.932861, PDE Loss: 50.525337, BC Loss: 101.744606, IC Loss: 11756.458008, LR: 0.00003906\n",
      "Epoch 4000, Total Loss: 2342.856689, PDE Loss: 50.536293, BC Loss: 101.343185, IC Loss: 11760.204102, LR: 0.00001953\n",
      "Epoch 4000, Total Loss: 2342.856689, PDE Loss: 50.536293, BC Loss: 101.343185, IC Loss: 11760.204102, LR: 0.00001953\n",
      "Epoch 4500, Total Loss: 2342.823730, PDE Loss: 50.541664, BC Loss: 101.160995, IC Loss: 11761.904297, LR: 0.00000488\n",
      "Epoch 4500, Total Loss: 2342.823730, PDE Loss: 50.541664, BC Loss: 101.160995, IC Loss: 11761.904297, LR: 0.00000488\n",
      "Epoch 4999, Total Loss: 2342.812256, PDE Loss: 50.543324, BC Loss: 101.103340, IC Loss: 11762.438477, LR: 0.00000122\n",
      "Epoch 4999, Total Loss: 2342.812256, PDE Loss: 50.543324, BC Loss: 101.103340, IC Loss: 11762.438477, LR: 0.00000122\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>█▅▄▄▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>final_bc_loss</td><td>▁</td></tr><tr><td>final_ic_loss</td><td>▁</td></tr><tr><td>final_pde_loss</td><td>▁</td></tr><tr><td>final_total_loss</td><td>▁</td></tr><tr><td>ic_loss</td><td>▂▂▁▁▁▃▄▄▄▅▆▆▇▇██████████████████████████</td></tr><tr><td>learning_rate</td><td>████████████▄▄▄▃▃▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>pde_loss</td><td>▁▁▃▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇█████████████████████</td></tr><tr><td>total_loss</td><td>█▃▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>bc_loss</td><td>101.10334</td></tr><tr><td>epoch</td><td>4999</td></tr><tr><td>final_bc_loss</td><td>101.10334</td></tr><tr><td>final_ic_loss</td><td>11762.43848</td></tr><tr><td>final_pde_loss</td><td>50.54332</td></tr><tr><td>final_total_loss</td><td>2342.81226</td></tr><tr><td>ic_loss</td><td>11762.43848</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>pde_loss</td><td>50.54332</td></tr><tr><td>total_loss</td><td>2342.81226</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">royal-sweep-6</strong> at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/vzcnpqmo' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep/runs/vzcnpqmo</a><br> View project at: <a href='https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/PINN_Architecture_Sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250715_135123-vzcnpqmo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent('zdv6nzua', function=train_pinn_sweep, count=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a33133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "star-pinn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
